# The model is trained using the .ini configuration file. After training,
# a copy of input config file will be created and stored in the directory,
# configs_train, for tracking.

[data]
# - Directory storing the label file. If cross_val is True,
#   the directory should contain label files with naming of 0.csv,
#   1.csv, etc.
label_folder  = ./data/cv/labels
#
# - Label files are in the form of csv, with first column storing
#   the paths to the spectra, and the rest of the columns storing
#   NORMALIZED labels.
# - Validation set is loaded only when set_val is True.
# - train_label: training label file
# - test_label: test label file
# - val_label: validation label file
train_label = train.csv
test_label = test.csv
val_label = valid.csv
#
# - Sepcify output version to store all training results.
# - log_folder: Storing outputs from writer functions with
#               the info of losses and hyperparameters.
output_version = test2
output_folder = ./${output_version}
log_folder    = ./${output_version}/loss_logging

[hypar]
# - Run cross-validations if True; otherwise, the model is
#   trained/tested on specified label files.
cross_valid = False
#
# - Test set ID. Also used as cross-validation fold ID
test_id = 0
#
# - Number of cross-validation folds. Only used when cross_valid
#   is True.
fold_num = 3
#
# - If True, apply train-validation-test splits;
#   otherwise, split labels into training and test sets.
set_val = False
#
# - Number of epochs
epochs = 10
#
# - Number of batches
batch = 10
#
# - Energy range of input spectra
energy_range = 0.0,120.0
#
# - !!Currently not implemented!! If True, load pretrained weights
pretrain = False
#
# - Column indices of label file starting with 1.
#   Column 0 is the spectra paths...
class_tag = 1,2,3,4
#
# - If True, convert spectra to log-scale.
set_log = False
#
# - Small number added to log-scale spectra to avoid
#   NaN.
# - Only used when set_log is True.
epsilon = 1e-5
#
# - Normalization method applied to input spectra.
# - Options are
# -- Multiply a constant; args: norm_method:const, norm_const:1e5
# -- Local Min-max normalization; args: norm_method:minmax
# -- Global Min-max normalization; args: norm_method:globalminmax,
#                                        norm_min_max:0,1
# -- Standarize normalization; args: norm_method:standard,
#                                    stand_mean:0.1, stand_std:0.01
norm_method = const
norm_const  = 1
#
# - Model name.
model_name = cae
#
# - Fully connected layer lengths.
mlp_in_length = 2960
#
# - Number of Residual layers.
num_layers = 4
#
# - Number of latent variables.
latent_size = 4
#
# - Optimizer; can be adam or sgd.
optim_type = adam
#
# - Initial learning rate.
lr = 1e-2
#
# - Apply weight decay if non-zero.
wdecay = 0
#
# - Momentum.
moment = 0
#
# - If True, apply scheduler for training.
use_scheduler = True
#
# - Reconstruction loss function; only support
#   mse (MSE), mae (MAE), bce (Binary Cross Entropy),
#   or poisson
loss_type = mse
#
# - Impose constrain term.
# - Options are
# ---- l1_all: MAE for all latent variables (code)
# ---- l1_part: MAE for partial code
# ---- l2_all: MSE for all latent variables (code)
# ---- l2_part: MSE for partial code
add_constrain = l1_all
#
# Number of code to constrain.
num_constr_codes = 4
#
# - Scalar multiplied to constrain loss before
#   added to the reconstruction loss.
add_weight = 0.1

[comment]
# - Comments stored in summary file
training_description = training

[pretrain]
# !!Currently not implemented!!
load_pretrain = False
pre_folder =
fold = 0
model = 0